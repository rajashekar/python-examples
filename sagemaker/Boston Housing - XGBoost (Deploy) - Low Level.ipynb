{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Boston Housing Prices\n",
    "\n",
    "## Using XGBoost in SageMaker (Deploy)\n",
    "\n",
    "_Deep Learning Nanodegree Program | Deployment_\n",
    "\n",
    "---\n",
    "\n",
    "As an introduction to using SageMaker's Low Level Python API we will look at a relatively simple problem. Namely, we will use the [Boston Housing Dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) to predict the median value of a home in the area of Boston Mass.\n",
    "\n",
    "The documentation reference for the API used in this notebook is the [SageMaker Developer's Guide](https://docs.aws.amazon.com/sagemaker/latest/dg/)\n",
    "\n",
    "## General Outline\n",
    "\n",
    "Typically, when using a notebook instance with SageMaker, you will proceed through the following steps. Of course, not every step will need to be done with each project. Also, there is quite a lot of room for variation in many of the steps, as you will see throughout these lessons.\n",
    "\n",
    "1. Download or otherwise retrieve the data.\n",
    "2. Process / Prepare the data.\n",
    "3. Upload the processed data to S3.\n",
    "4. Train a chosen model.\n",
    "5. Test the trained model (typically using a batch transform job).\n",
    "6. Deploy the trained model.\n",
    "7. Use the deployed model.\n",
    "\n",
    "In this notebook we will be skipping step 5, testing the model. We will still test the model but we will do so by first deploying it and then sending the test data to the deployed model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Setting up the notebook\n",
    "\n",
    "We begin by setting up all of the necessary bits required to run our notebook. To start that means loading all of the Python modules we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_boston\n",
    "import sklearn.model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the modules above, we need to import the various bits of SageMaker that we will be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# This is an object that represents the SageMaker session that we are currently operating in. This\n",
    "# object contains some useful information that we will need to access later such as our region.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# This is an object that represents the IAM role that we are currently assigned. When we construct\n",
    "# and launch the training job later we will need to tell it what IAM role it should have. Since our\n",
    "# use case is relatively simple we will simply assign the training job the role we currently have.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Downloading the data\n",
    "\n",
    "Fortunately, this dataset can be retrieved using sklearn and so this step is relatively straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Preparing and splitting the data\n",
    "\n",
    "Given that this is clean tabular data, we don't need to do any processing. However, we do need to split the rows in the dataset up into train, test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we package up the input data and the target variable (the median value) as pandas dataframes. This\n",
    "# will make saving the data to a file a little easier later on.\n",
    "\n",
    "X_bos_pd = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "Y_bos_pd = pd.DataFrame(boston.target)\n",
    "\n",
    "# We split the dataset into 2/3 training and 1/3 testing sets.\n",
    "X_train, X_test, Y_train, Y_test = sklearn.model_selection.train_test_split(X_bos_pd, Y_bos_pd, test_size=0.33)\n",
    "\n",
    "# Then we split the training set further into 2/3 training and 1/3 validation sets.\n",
    "X_train, X_val, Y_train, Y_val = sklearn.model_selection.train_test_split(X_train, Y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Uploading the training and validation files to S3\n",
    "\n",
    "When a training job is constructed using SageMaker, a container is executed which performs the training operation. This container is given access to data that is stored in S3. This means that we need to upload the data we want to use for training to S3. We can use the SageMaker API to do this and hide some of the details.\n",
    "\n",
    "### Save the data locally\n",
    "\n",
    "First we need to create the train and validation csv files which we will then upload to S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is our local data directory. We need to make sure that it exists.\n",
    "data_dir = '../data/boston'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to save our train and validation data to csv files. Note that we make sure not to include header\n",
    "# information or an index as this is required by the built in algorithms provided by Amazon. Also, it is assumed\n",
    "# that the first entry in each row is the target variable.\n",
    "\n",
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation.csv'), header=False, index=False)\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload to S3\n",
    "\n",
    "Since we are currently running inside of a SageMaker session, we can use the object which represents this session to upload our data to the 'default' S3 bucket. Note that it is good practice to provide a custom prefix (essentially an S3 folder) to make sure that you don't accidentally interfere with data uploaded from some other notebook or project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'boston-xgboost-deploy-ll'\n",
    "\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'us-west-1'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.boto_region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Train and construct the XGBoost model\n",
    "\n",
    "Now that we have the training and validation data uploaded to S3, we can construct a training job for our XGBoost model and build the model itself.\n",
    "\n",
    "### Set up the training job\n",
    "\n",
    "First, we will set up and execute a training job for our model. To do this we need to specify some information that SageMaker will use to set up and properly execute the computation. For additional documentation on constructing a training job, see the [CreateTrainingJob API](https://docs.aws.amazon.com/sagemaker/latest/dg/API_CreateTrainingJob.html) reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:There is a more up to date SageMaker XGBoost image. To use the newer image, please set 'repo_version'='0.90-1'. For example:\n",
      "\tget_image_uri(region, 'xgboost', '0.90-1').\n"
     ]
    }
   ],
   "source": [
    "# We will need to know the name of the container that we want to use for training. SageMaker provides\n",
    "# a nice utility method to construct this for us.\n",
    "container = get_image_uri(session.boto_region_name, 'xgboost')\n",
    "\n",
    "# We now specify the parameters we wish to use for our training job\n",
    "training_params = {}\n",
    "\n",
    "# We need to specify the permissions that this training job will have. For our purposes we can use\n",
    "# the same permissions that our current SageMaker session has.\n",
    "training_params['RoleArn'] = role\n",
    "\n",
    "# Here we describe the algorithm we wish to use. The most important part is the container which\n",
    "# contains the training code.\n",
    "training_params['AlgorithmSpecification'] = {\n",
    "    \"TrainingImage\": container,\n",
    "    \"TrainingInputMode\": \"File\"\n",
    "}\n",
    "\n",
    "# We also need to say where we would like the resulting model artifacst stored.\n",
    "training_params['OutputDataConfig'] = {\n",
    "    \"S3OutputPath\": \"s3://\" + session.default_bucket() + \"/\" + prefix + \"/output\"\n",
    "}\n",
    "\n",
    "# We also need to set some parameters for the training job itself. Namely we need to describe what sort of\n",
    "# compute instance we wish to use along with a stopping condition to handle the case that there is\n",
    "# some sort of error and the training script doesn't terminate.\n",
    "training_params['ResourceConfig'] = {\n",
    "    \"InstanceCount\": 1,\n",
    "    \"InstanceType\": \"ml.m4.xlarge\",\n",
    "    \"VolumeSizeInGB\": 5\n",
    "}\n",
    "    \n",
    "training_params['StoppingCondition'] = {\n",
    "    \"MaxRuntimeInSeconds\": 86400\n",
    "}\n",
    "\n",
    "# Next we set the algorithm specific hyperparameters. You may wish to change these to see what effect\n",
    "# there is on the resulting model.\n",
    "training_params['HyperParameters'] = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.8\",\n",
    "    \"objective\": \"reg:linear\",\n",
    "    \"early_stopping_rounds\": \"10\",\n",
    "    \"num_round\": \"200\"\n",
    "}\n",
    "\n",
    "# Now we need to tell SageMaker where the data should be retrieved from.\n",
    "training_params['InputDataConfig'] = [\n",
    "    {\n",
    "        \"ChannelName\": \"train\",\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": train_location,\n",
    "                \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "            }\n",
    "        },\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"CompressionType\": \"None\"\n",
    "    },\n",
    "    {\n",
    "        \"ChannelName\": \"validation\",\n",
    "        \"DataSource\": {\n",
    "            \"S3DataSource\": {\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"S3Uri\": val_location,\n",
    "                \"S3DataDistributionType\": \"FullyReplicated\"\n",
    "            }\n",
    "        },\n",
    "        \"ContentType\": \"csv\",\n",
    "        \"CompressionType\": \"None\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the training job\n",
    "\n",
    "Now that we've built the dict containing the training job parameters, we can ask SageMaker to execute the job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to choose a training job name. This is useful for if we want to recall information about our\n",
    "# training job at a later date. Note that SageMaker requires a training job name and that the name needs to\n",
    "# be unique, which we accomplish by appending the current timestamp.\n",
    "training_job_name = \"boston-xgboost-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "training_params['TrainingJobName'] = training_job_name\n",
    "\n",
    "# And now we ask SageMaker to create (and execute) the training job\n",
    "training_job = session.sagemaker_client.create_training_job(**training_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training job has now been created by SageMaker and is currently running. Since we need the output of the training job, we may wish to wait until it has finished. We can do so by asking SageMaker to output the logs generated by the training job and continue doing so until the training job terminates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-10 11:55:56 Starting - Preparing the instances for training\n",
      "2020-05-10 11:55:56 Downloading - Downloading input data\n",
      "2020-05-10 11:55:56 Training - Training image download completed. Training in progress.\n",
      "2020-05-10 11:55:56 Uploading - Uploading generated training model\n",
      "2020-05-10 11:55:56 Completed - Training job completed\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2020-05-10:11:55:44:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2020-05-10:11:55:44:INFO] File size need to be processed in the node: 0.02mb. Available memory size in the node: 8499.86mb\u001b[0m\n",
      "\u001b[34m[2020-05-10:11:55:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[11:55:44] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[11:55:44] 227x13 matrix with 2951 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2020-05-10:11:55:44:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[11:55:44] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[11:55:44] 112x13 matrix with 1456 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:19.087#011validation-rmse:19.9791\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-rmse' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-rmse hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:15.5659#011validation-rmse:16.4018\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:12.8385#011validation-rmse:13.8192\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:10.6045#011validation-rmse:11.6499\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:8.87917#011validation-rmse:10.1233\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:7.39355#011validation-rmse:8.87787\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:6.19015#011validation-rmse:7.89735\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:5.27214#011validation-rmse:7.16179\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:4.56279#011validation-rmse:6.55514\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:3.99415#011validation-rmse:6.16051\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:3.56544#011validation-rmse:5.8517\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:3.16513#011validation-rmse:5.5467\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:2.87468#011validation-rmse:5.38464\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:2.65775#011validation-rmse:5.2419\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:2.49672#011validation-rmse:5.09959\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:2.35975#011validation-rmse:5.05069\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:2.24928#011validation-rmse:5.04239\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:2.18048#011validation-rmse:5.02241\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:2.09527#011validation-rmse:4.93428\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:1.99547#011validation-rmse:4.87477\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:1.92682#011validation-rmse:4.8729\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:1.87534#011validation-rmse:4.91007\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:1.81112#011validation-rmse:4.85124\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:1.76361#011validation-rmse:4.83314\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:1.7277#011validation-rmse:4.79231\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:1.66744#011validation-rmse:4.75956\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:1.61361#011validation-rmse:4.72623\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:1.57681#011validation-rmse:4.69455\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:1.55787#011validation-rmse:4.71168\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:1.52271#011validation-rmse:4.71002\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:1.47126#011validation-rmse:4.70959\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:1.4521#011validation-rmse:4.69105\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:1.43505#011validation-rmse:4.6836\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:1.40059#011validation-rmse:4.6893\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:1.39163#011validation-rmse:4.71282\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:1.36085#011validation-rmse:4.71891\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:1.32452#011validation-rmse:4.69414\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:1.2791#011validation-rmse:4.67824\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:1.2595#011validation-rmse:4.65522\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:1.2393#011validation-rmse:4.65666\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 4 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:1.23149#011validation-rmse:4.64203\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:1.19926#011validation-rmse:4.66561\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:1.18325#011validation-rmse:4.66088\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:1.16311#011validation-rmse:4.67997\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:1.14164#011validation-rmse:4.6799\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:1.11752#011validation-rmse:4.65104\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:1.0881#011validation-rmse:4.64754\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 16 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:1.08574#011validation-rmse:4.63151\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:1.07548#011validation-rmse:4.64469\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 10 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:1.07001#011validation-rmse:4.65886\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 0 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:1.05089#011validation-rmse:4.65733\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:1.02391#011validation-rmse:4.63728\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 14 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:1.01538#011validation-rmse:4.61933\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 14 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:1.00806#011validation-rmse:4.61949\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:0.981141#011validation-rmse:4.62339\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 22 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:0.971854#011validation-rmse:4.60734\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 10 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:0.96933#011validation-rmse:4.59517\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 16 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:0.967402#011validation-rmse:4.59709\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:0.9477#011validation-rmse:4.61057\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 6 extra nodes, 10 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:0.941316#011validation-rmse:4.58972\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:0.922865#011validation-rmse:4.57199\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 8 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:0.914613#011validation-rmse:4.58126\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:0.914631#011validation-rmse:4.58095\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:0.899428#011validation-rmse:4.56588\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 10 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:0.896734#011validation-rmse:4.56683\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:0.896713#011validation-rmse:4.56805\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:0.887809#011validation-rmse:4.5748\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:0.887837#011validation-rmse:4.57346\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 16 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:0.883353#011validation-rmse:4.54253\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 16 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[69]#011train-rmse:0.883012#011validation-rmse:4.52144\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:0.87208#011validation-rmse:4.51907\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 22 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:0.87203#011validation-rmse:4.52112\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:0.861119#011validation-rmse:4.52299\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 32 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[73]#011train-rmse:0.861096#011validation-rmse:4.52381\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 16 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[74]#011train-rmse:0.86118#011validation-rmse:4.5218\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 12 pruned nodes, max_depth=3\u001b[0m\n",
      "\u001b[34m[75]#011train-rmse:0.852159#011validation-rmse:4.52698\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 12 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[76]#011train-rmse:0.852139#011validation-rmse:4.52764\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 10 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[77]#011train-rmse:0.844998#011validation-rmse:4.5461\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[78]#011train-rmse:0.844992#011validation-rmse:4.5465\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[79]#011train-rmse:0.836372#011validation-rmse:4.53373\u001b[0m\n",
      "\u001b[34m[11:55:44] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[80]#011train-rmse:0.836493#011validation-rmse:4.53608\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:0.87208#011validation-rmse:4.51907\n",
      "\u001b[0m\n",
      "Training seconds: 63\n",
      "Billable seconds: 63\n"
     ]
    }
   ],
   "source": [
    "session.logs_for_job(training_job_name, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model\n",
    "\n",
    "Now that the training job has completed, we have some model artifacts which we can use to build a model. Note that here we mean SageMaker's definition of a model, which is a collection of information about a specific algorithm along with the artifacts which result from a training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We begin by asking SageMaker to describe for us the results of the training job. The data structure\n",
    "# returned contains a lot more information than we currently need, try checking it out yourself in\n",
    "# more detail.\n",
    "training_job_info = session.sagemaker_client.describe_training_job(TrainingJobName=training_job_name)\n",
    "\n",
    "model_artifacts = training_job_info['ModelArtifacts']['S3ModelArtifacts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just like when we created a training job, the model name must be unique\n",
    "model_name = training_job_name + \"-model\"\n",
    "\n",
    "# We also need to tell SageMaker which container should be used for inference and where it should\n",
    "# retrieve the model artifacts from. In our case, the xgboost container that we used for training\n",
    "# can also be used for inference.\n",
    "primary_container = {\n",
    "    \"Image\": container,\n",
    "    \"ModelDataUrl\": model_artifacts\n",
    "}\n",
    "\n",
    "# And lastly we construct the SageMaker model\n",
    "model_info = session.sagemaker_client.create_model(\n",
    "                                ModelName = model_name,\n",
    "                                ExecutionRoleArn = role,\n",
    "                                PrimaryContainer = primary_container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test the trained model\n",
    "\n",
    "We will be skipping this step for now. We will still test our trained model but we are going to do it by using the deployed model, rather than setting up a batch transform job.\n",
    "\n",
    "## Step 6: Create and deploy the endpoint\n",
    "\n",
    "Now that we have trained and constructed a model it is time to build the associated endpoint and deploy it. As in the earlier steps, we first need to construct the appropriate configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As before, we need to give our endpoint configuration a name which should be unique\n",
    "endpoint_config_name = \"boston-xgboost-endpoint-config-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# And then we ask SageMaker to construct the endpoint configuration\n",
    "endpoint_config_info = session.sagemaker_client.create_endpoint_config(\n",
    "                            EndpointConfigName = endpoint_config_name,\n",
    "                            ProductionVariants = [{\n",
    "                                \"InstanceType\": \"ml.m4.xlarge\",\n",
    "                                \"InitialVariantWeight\": 1,\n",
    "                                \"InitialInstanceCount\": 1,\n",
    "                                \"ModelName\": model_name,\n",
    "                                \"VariantName\": \"AllTraffic\"\n",
    "                            }])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now that the endpoint configuration has been created we can deploy the endpoint itself.\n",
    "\n",
    "**NOTE:** When deploying a model you are asking SageMaker to launch an compute instance that will wait for data to be sent to it. As a result, this compute instance will continue to run until *you* shut it down. This is important to know since the cost of a deployed endpoint depends on how long it has been running for.\n",
    "\n",
    "In other words **If you are no longer using a deployed endpoint, shut it down!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we need a unique name for our endpoint\n",
    "endpoint_name = \"boston-xgboost-endpoint-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "# And then we can deploy our endpoint\n",
    "endpoint_info = session.sagemaker_client.create_endpoint(\n",
    "                    EndpointName = endpoint_name,\n",
    "                    EndpointConfigName = endpoint_config_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like when we created a training job, SageMaker is now requisitioning and launching our endpoint. Since we can't do much until the endpoint has been completely deployed we can wait for it to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "endpoint_dec = session.wait_for_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Use the model\n",
    "\n",
    "Now that our model is trained and deployed we can send test data to it and evaluate the results. Here, because our test data is so small, we can send it all using a single call to our endpoint. If our test dataset was larger we would need to split it up and send the data in chunks, making sure to accumulate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>2.31390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>5.880</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.3887</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>348.13</td>\n",
       "      <td>12.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.03584</td>\n",
       "      <td>80.0</td>\n",
       "      <td>3.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3980</td>\n",
       "      <td>6.290</td>\n",
       "      <td>17.8</td>\n",
       "      <td>6.6115</td>\n",
       "      <td>4.0</td>\n",
       "      <td>337.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.01965</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>6.230</td>\n",
       "      <td>31.5</td>\n",
       "      <td>9.0892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>241.0</td>\n",
       "      <td>18.2</td>\n",
       "      <td>341.60</td>\n",
       "      <td>12.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.08873</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>5.963</td>\n",
       "      <td>45.7</td>\n",
       "      <td>6.8147</td>\n",
       "      <td>4.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>395.56</td>\n",
       "      <td>13.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>0.06211</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4290</td>\n",
       "      <td>6.490</td>\n",
       "      <td>44.4</td>\n",
       "      <td>8.7921</td>\n",
       "      <td>1.0</td>\n",
       "      <td>335.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>0.10659</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>5.936</td>\n",
       "      <td>19.5</td>\n",
       "      <td>10.5857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>376.04</td>\n",
       "      <td>5.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0.55007</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>7.206</td>\n",
       "      <td>91.6</td>\n",
       "      <td>1.9301</td>\n",
       "      <td>5.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>387.89</td>\n",
       "      <td>8.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>1.12658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.012</td>\n",
       "      <td>88.0</td>\n",
       "      <td>1.6102</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>343.28</td>\n",
       "      <td>12.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.51183</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>7.358</td>\n",
       "      <td>71.6</td>\n",
       "      <td>4.1480</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>390.07</td>\n",
       "      <td>4.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.01096</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3890</td>\n",
       "      <td>6.453</td>\n",
       "      <td>31.9</td>\n",
       "      <td>7.3073</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>394.72</td>\n",
       "      <td>8.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.01381</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4220</td>\n",
       "      <td>7.875</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.6484</td>\n",
       "      <td>4.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>394.23</td>\n",
       "      <td>2.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.80271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.456</td>\n",
       "      <td>36.6</td>\n",
       "      <td>3.7965</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>288.99</td>\n",
       "      <td>11.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.25179</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.570</td>\n",
       "      <td>98.1</td>\n",
       "      <td>3.7979</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>376.57</td>\n",
       "      <td>21.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>12.24720</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5840</td>\n",
       "      <td>5.837</td>\n",
       "      <td>59.7</td>\n",
       "      <td>1.9976</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>24.65</td>\n",
       "      <td>15.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.05023</td>\n",
       "      <td>35.0</td>\n",
       "      <td>6.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4379</td>\n",
       "      <td>5.706</td>\n",
       "      <td>28.4</td>\n",
       "      <td>6.6407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>16.9</td>\n",
       "      <td>394.02</td>\n",
       "      <td>12.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.52058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>6.631</td>\n",
       "      <td>76.5</td>\n",
       "      <td>4.1480</td>\n",
       "      <td>8.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>388.45</td>\n",
       "      <td>9.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.04462</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4260</td>\n",
       "      <td>6.619</td>\n",
       "      <td>70.4</td>\n",
       "      <td>5.4007</td>\n",
       "      <td>4.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>395.63</td>\n",
       "      <td>7.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>3.84970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>6.395</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.5052</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.34</td>\n",
       "      <td>13.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.22438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>6.027</td>\n",
       "      <td>79.7</td>\n",
       "      <td>2.4982</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>4.81213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>6.701</td>\n",
       "      <td>90.0</td>\n",
       "      <td>2.5975</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>255.23</td>\n",
       "      <td>16.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>24.39380</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>4.652</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.4672</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>28.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>3.67367</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5830</td>\n",
       "      <td>6.312</td>\n",
       "      <td>51.9</td>\n",
       "      <td>3.9917</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>388.62</td>\n",
       "      <td>10.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>4.42228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5840</td>\n",
       "      <td>6.003</td>\n",
       "      <td>94.5</td>\n",
       "      <td>2.5403</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>331.29</td>\n",
       "      <td>21.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.03551</td>\n",
       "      <td>25.0</td>\n",
       "      <td>4.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4260</td>\n",
       "      <td>6.167</td>\n",
       "      <td>46.7</td>\n",
       "      <td>5.4007</td>\n",
       "      <td>4.0</td>\n",
       "      <td>281.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>390.64</td>\n",
       "      <td>7.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.07896</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4370</td>\n",
       "      <td>6.273</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.2515</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.92</td>\n",
       "      <td>6.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>0.10469</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4470</td>\n",
       "      <td>7.267</td>\n",
       "      <td>49.0</td>\n",
       "      <td>4.7872</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>389.25</td>\n",
       "      <td>6.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>9.91655</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6930</td>\n",
       "      <td>5.852</td>\n",
       "      <td>77.8</td>\n",
       "      <td>1.5004</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>338.16</td>\n",
       "      <td>29.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>3.53501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>6.152</td>\n",
       "      <td>82.6</td>\n",
       "      <td>1.7455</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>88.01</td>\n",
       "      <td>15.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.14932</td>\n",
       "      <td>25.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4530</td>\n",
       "      <td>5.741</td>\n",
       "      <td>66.2</td>\n",
       "      <td>7.2254</td>\n",
       "      <td>8.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>395.11</td>\n",
       "      <td>13.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.01501</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>7.923</td>\n",
       "      <td>24.8</td>\n",
       "      <td>5.8850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>395.52</td>\n",
       "      <td>3.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.01432</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4110</td>\n",
       "      <td>6.816</td>\n",
       "      <td>40.5</td>\n",
       "      <td>8.3248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>392.90</td>\n",
       "      <td>3.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.06911</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4370</td>\n",
       "      <td>6.739</td>\n",
       "      <td>30.8</td>\n",
       "      <td>6.4798</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>389.71</td>\n",
       "      <td>4.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>0.03113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4420</td>\n",
       "      <td>6.014</td>\n",
       "      <td>48.5</td>\n",
       "      <td>8.0136</td>\n",
       "      <td>3.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>385.64</td>\n",
       "      <td>10.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.10574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6090</td>\n",
       "      <td>5.983</td>\n",
       "      <td>98.8</td>\n",
       "      <td>1.8681</td>\n",
       "      <td>4.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>20.1</td>\n",
       "      <td>390.11</td>\n",
       "      <td>18.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4690</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.08244</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4280</td>\n",
       "      <td>6.481</td>\n",
       "      <td>18.5</td>\n",
       "      <td>6.1899</td>\n",
       "      <td>6.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>379.41</td>\n",
       "      <td>6.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0.05602</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4880</td>\n",
       "      <td>7.831</td>\n",
       "      <td>53.6</td>\n",
       "      <td>3.1992</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.63</td>\n",
       "      <td>4.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0.03049</td>\n",
       "      <td>55.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4840</td>\n",
       "      <td>6.874</td>\n",
       "      <td>28.1</td>\n",
       "      <td>6.4654</td>\n",
       "      <td>5.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>387.97</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>0.06129</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.4429</td>\n",
       "      <td>7.645</td>\n",
       "      <td>49.7</td>\n",
       "      <td>5.2119</td>\n",
       "      <td>5.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>377.07</td>\n",
       "      <td>3.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>3.83684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7700</td>\n",
       "      <td>6.251</td>\n",
       "      <td>91.1</td>\n",
       "      <td>2.2955</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>350.65</td>\n",
       "      <td>14.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>0.17331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>5.707</td>\n",
       "      <td>54.0</td>\n",
       "      <td>2.3817</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>12.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>9.51363</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>6.728</td>\n",
       "      <td>94.1</td>\n",
       "      <td>2.4961</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>6.68</td>\n",
       "      <td>18.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.05425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>6.315</td>\n",
       "      <td>73.4</td>\n",
       "      <td>3.3175</td>\n",
       "      <td>5.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>16.6</td>\n",
       "      <td>395.60</td>\n",
       "      <td>6.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>9.33889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6790</td>\n",
       "      <td>6.380</td>\n",
       "      <td>95.6</td>\n",
       "      <td>1.9682</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>60.72</td>\n",
       "      <td>24.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.04684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4890</td>\n",
       "      <td>6.417</td>\n",
       "      <td>66.1</td>\n",
       "      <td>3.0923</td>\n",
       "      <td>2.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.18</td>\n",
       "      <td>8.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.05789</td>\n",
       "      <td>12.5</td>\n",
       "      <td>6.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4090</td>\n",
       "      <td>5.878</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6.4980</td>\n",
       "      <td>4.0</td>\n",
       "      <td>345.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>396.21</td>\n",
       "      <td>8.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>4.64689</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>6.980</td>\n",
       "      <td>67.6</td>\n",
       "      <td>2.5329</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>374.68</td>\n",
       "      <td>11.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.03510</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4161</td>\n",
       "      <td>7.853</td>\n",
       "      <td>33.2</td>\n",
       "      <td>5.1180</td>\n",
       "      <td>4.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>392.78</td>\n",
       "      <td>3.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0.26838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5850</td>\n",
       "      <td>5.794</td>\n",
       "      <td>70.6</td>\n",
       "      <td>2.8927</td>\n",
       "      <td>6.0</td>\n",
       "      <td>391.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>14.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.35114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4930</td>\n",
       "      <td>6.041</td>\n",
       "      <td>49.9</td>\n",
       "      <td>4.7211</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.98843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5380</td>\n",
       "      <td>5.813</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.0952</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>394.54</td>\n",
       "      <td>19.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.32982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>5.822</td>\n",
       "      <td>95.4</td>\n",
       "      <td>2.4699</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>388.69</td>\n",
       "      <td>15.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>0.82526</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>7.327</td>\n",
       "      <td>94.5</td>\n",
       "      <td>2.0788</td>\n",
       "      <td>5.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>393.42</td>\n",
       "      <td>11.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>3.69311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>6.376</td>\n",
       "      <td>88.4</td>\n",
       "      <td>2.5671</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>391.43</td>\n",
       "      <td>14.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.15876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>5.961</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.2873</td>\n",
       "      <td>4.0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>376.94</td>\n",
       "      <td>9.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>0.18159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4930</td>\n",
       "      <td>6.376</td>\n",
       "      <td>54.3</td>\n",
       "      <td>4.5404</td>\n",
       "      <td>5.0</td>\n",
       "      <td>287.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>396.90</td>\n",
       "      <td>6.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>5.82115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>6.513</td>\n",
       "      <td>89.9</td>\n",
       "      <td>2.8016</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>393.82</td>\n",
       "      <td>10.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>2.24236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>5.854</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.4220</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>395.11</td>\n",
       "      <td>11.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>4.75237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7130</td>\n",
       "      <td>6.525</td>\n",
       "      <td>86.5</td>\n",
       "      <td>2.4358</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>50.92</td>\n",
       "      <td>18.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>22.59710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>89.5</td>\n",
       "      <td>1.5184</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>31.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows  13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM     ZN  INDUS  CHAS     NOX     RM    AGE      DIS   RAD    TAX  \\\n",
       "171   2.31390    0.0  19.58   0.0  0.6050  5.880   97.3   2.3887   5.0  403.0   \n",
       "65    0.03584   80.0   3.37   0.0  0.3980  6.290   17.8   6.6115   4.0  337.0   \n",
       "286   0.01965   80.0   1.76   0.0  0.3850  6.230   31.5   9.0892   1.0  241.0   \n",
       "50    0.08873   21.0   5.64   0.0  0.4390  5.963   45.7   6.8147   4.0  243.0   \n",
       "350   0.06211   40.0   1.25   0.0  0.4290  6.490   44.4   8.7921   1.0  335.0   \n",
       "355   0.10659   80.0   1.91   0.0  0.4130  5.936   19.5  10.5857   4.0  334.0   \n",
       "264   0.55007   20.0   3.97   0.0  0.6470  7.206   91.6   1.9301   5.0  264.0   \n",
       "152   1.12658    0.0  19.58   1.0  0.8710  5.012   88.0   1.6102   5.0  403.0   \n",
       "237   0.51183    0.0   6.20   0.0  0.5070  7.358   71.6   4.1480   8.0  307.0   \n",
       "285   0.01096   55.0   2.25   0.0  0.3890  6.453   31.9   7.3073   1.0  300.0   \n",
       "195   0.01381   80.0   0.46   0.0  0.4220  7.875   32.0   5.6484   4.0  255.0   \n",
       "18    0.80271    0.0   8.14   0.0  0.5380  5.456   36.6   3.7965   4.0  307.0   \n",
       "20    1.25179    0.0   8.14   0.0  0.5380  5.570   98.1   3.7979   4.0  307.0   \n",
       "426  12.24720    0.0  18.10   0.0  0.5840  5.837   59.7   1.9976  24.0  666.0   \n",
       "331   0.05023   35.0   6.06   0.0  0.4379  5.706   28.4   6.6407   1.0  304.0   \n",
       "236   0.52058    0.0   6.20   1.0  0.5070  6.631   76.5   4.1480   8.0  307.0   \n",
       "81    0.04462   25.0   4.86   0.0  0.4260  6.619   70.4   5.4007   4.0  281.0   \n",
       "357   3.84970    0.0  18.10   1.0  0.7700  6.395   91.0   2.5052  24.0  666.0   \n",
       "500   0.22438    0.0   9.69   0.0  0.5850  6.027   79.7   2.4982   6.0  391.0   \n",
       "460   4.81213    0.0  18.10   0.0  0.7130  6.701   90.0   2.5975  24.0  666.0   \n",
       "386  24.39380    0.0  18.10   0.0  0.7000  4.652  100.0   1.4672  24.0  666.0   \n",
       "485   3.67367    0.0  18.10   0.0  0.5830  6.312   51.9   3.9917  24.0  666.0   \n",
       "467   4.42228    0.0  18.10   0.0  0.5840  6.003   94.5   2.5403  24.0  666.0   \n",
       "83    0.03551   25.0   4.86   0.0  0.4260  6.167   46.7   5.4007   4.0  281.0   \n",
       "74    0.07896    0.0  12.83   0.0  0.4370  6.273    6.0   4.2515   5.0  398.0   \n",
       "276   0.10469   40.0   6.41   1.0  0.4470  7.267   49.0   4.7872   4.0  254.0   \n",
       "399   9.91655    0.0  18.10   0.0  0.6930  5.852   77.8   1.5004  24.0  666.0   \n",
       "155   3.53501    0.0  19.58   1.0  0.8710  6.152   82.6   1.7455   5.0  403.0   \n",
       "60    0.14932   25.0   5.13   0.0  0.4530  5.741   66.2   7.2254   8.0  284.0   \n",
       "283   0.01501   90.0   1.21   1.0  0.4010  7.923   24.8   5.8850   1.0  198.0   \n",
       "..        ...    ...    ...   ...     ...    ...    ...      ...   ...    ...   \n",
       "57    0.01432  100.0   1.32   0.0  0.4110  6.816   40.5   8.3248   5.0  256.0   \n",
       "191   0.06911   45.0   3.44   0.0  0.4370  6.739   30.8   6.4798   5.0  398.0   \n",
       "345   0.03113    0.0   4.39   0.0  0.4420  6.014   48.5   8.0136   3.0  352.0   \n",
       "491   0.10574    0.0  27.74   0.0  0.6090  5.983   98.8   1.8681   4.0  711.0   \n",
       "2     0.02729    0.0   7.07   0.0  0.4690  7.185   61.1   4.9671   2.0  242.0   \n",
       "238   0.08244   30.0   4.93   0.0  0.4280  6.481   18.5   6.1899   6.0  300.0   \n",
       "186   0.05602    0.0   2.46   0.0  0.4880  7.831   53.6   3.1992   3.0  193.0   \n",
       "344   0.03049   55.0   3.78   0.0  0.4840  6.874   28.1   6.4654   5.0  370.0   \n",
       "282   0.06129   20.0   3.33   1.0  0.4429  7.645   49.7   5.2119   5.0  216.0   \n",
       "361   3.83684    0.0  18.10   0.0  0.7700  6.251   91.1   2.2955  24.0  666.0   \n",
       "493   0.17331    0.0   9.69   0.0  0.5850  5.707   54.0   2.3817   6.0  391.0   \n",
       "454   9.51363    0.0  18.10   0.0  0.7130  6.728   94.1   2.4961  24.0  666.0   \n",
       "177   0.05425    0.0   4.05   0.0  0.5100  6.315   73.4   3.3175   5.0  296.0   \n",
       "429   9.33889    0.0  18.10   0.0  0.6790  6.380   95.6   1.9682  24.0  666.0   \n",
       "90    0.04684    0.0   3.41   0.0  0.4890  6.417   66.1   3.0923   2.0  270.0   \n",
       "67    0.05789   12.5   6.07   0.0  0.4090  5.878   21.4   6.4980   4.0  345.0   \n",
       "473   4.64689    0.0  18.10   0.0  0.6140  6.980   67.6   2.5329  24.0  666.0   \n",
       "203   0.03510   95.0   2.68   0.0  0.4161  7.853   33.2   5.1180   4.0  224.0   \n",
       "497   0.26838    0.0   9.69   0.0  0.5850  5.794   70.6   2.8927   6.0  391.0   \n",
       "322   0.35114    0.0   7.38   0.0  0.4930  6.041   49.9   4.7211   5.0  287.0   \n",
       "23    0.98843    0.0   8.14   0.0  0.5380  5.813  100.0   4.0952   4.0  307.0   \n",
       "133   0.32982    0.0  21.89   0.0  0.6240  5.822   95.4   2.4699   4.0  437.0   \n",
       "263   0.82526   20.0   3.97   0.0  0.6470  7.327   94.5   2.0788   5.0  264.0   \n",
       "461   3.69311    0.0  18.10   0.0  0.7130  6.376   88.4   2.5671  24.0  666.0   \n",
       "71    0.15876    0.0  10.81   0.0  0.4130  5.961   17.5   5.2873   4.0  305.0   \n",
       "321   0.18159    0.0   7.38   0.0  0.4930  6.376   54.3   4.5404   5.0  287.0   \n",
       "463   5.82115    0.0  18.10   0.0  0.7130  6.513   89.9   2.8016  24.0  666.0   \n",
       "164   2.24236    0.0  19.58   0.0  0.6050  5.854   91.8   2.4220   5.0  403.0   \n",
       "455   4.75237    0.0  18.10   0.0  0.7130  6.525   86.5   2.4358  24.0  666.0   \n",
       "387  22.59710    0.0  18.10   0.0  0.7000  5.000   89.5   1.5184  24.0  666.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "171     14.7  348.13  12.03  \n",
       "65      16.1  396.90   4.67  \n",
       "286     18.2  341.60  12.93  \n",
       "50      16.8  395.56  13.45  \n",
       "350     19.7  396.90   5.98  \n",
       "355     22.0  376.04   5.57  \n",
       "264     13.0  387.89   8.10  \n",
       "152     14.7  343.28  12.12  \n",
       "237     17.4  390.07   4.73  \n",
       "285     15.3  394.72   8.23  \n",
       "195     14.4  394.23   2.97  \n",
       "18      21.0  288.99  11.69  \n",
       "20      21.0  376.57  21.02  \n",
       "426     20.2   24.65  15.69  \n",
       "331     16.9  394.02  12.43  \n",
       "236     17.4  388.45   9.54  \n",
       "81      19.0  395.63   7.22  \n",
       "357     20.2  391.34  13.27  \n",
       "500     19.2  396.90  14.33  \n",
       "460     20.2  255.23  16.42  \n",
       "386     20.2  396.90  28.28  \n",
       "485     20.2  388.62  10.58  \n",
       "467     20.2  331.29  21.32  \n",
       "83      19.0  390.64   7.51  \n",
       "74      18.7  394.92   6.78  \n",
       "276     17.6  389.25   6.05  \n",
       "399     20.2  338.16  29.97  \n",
       "155     14.7   88.01  15.02  \n",
       "60      19.7  395.11  13.15  \n",
       "283     13.6  395.52   3.16  \n",
       "..       ...     ...    ...  \n",
       "57      15.1  392.90   3.95  \n",
       "191     15.2  389.71   4.69  \n",
       "345     18.8  385.64  10.53  \n",
       "491     20.1  390.11  18.07  \n",
       "2       17.8  392.83   4.03  \n",
       "238     16.6  379.41   6.36  \n",
       "186     17.8  392.63   4.45  \n",
       "344     17.6  387.97   4.61  \n",
       "282     14.9  377.07   3.01  \n",
       "361     20.2  350.65  14.19  \n",
       "493     19.2  396.90  12.01  \n",
       "454     20.2    6.68  18.71  \n",
       "177     16.6  395.60   6.29  \n",
       "429     20.2   60.72  24.08  \n",
       "90      17.8  392.18   8.81  \n",
       "67      18.9  396.21   8.10  \n",
       "473     20.2  374.68  11.66  \n",
       "203     14.7  392.78   3.81  \n",
       "497     19.2  396.90  14.10  \n",
       "322     19.6  396.90   7.70  \n",
       "23      21.0  394.54  19.88  \n",
       "133     21.2  388.69  15.03  \n",
       "263     13.0  393.42  11.25  \n",
       "461     20.2  391.43  14.65  \n",
       "71      19.2  376.94   9.88  \n",
       "321     19.6  396.90   6.87  \n",
       "463     20.2  393.82  10.29  \n",
       "164     14.7  395.11  11.64  \n",
       "455     20.2   50.92  18.13  \n",
       "387     20.2  396.90  31.99  \n",
       "\n",
       "[167 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.31390e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        3.48130e+02, 1.20300e+01],\n",
       "       [3.58400e-02, 8.00000e+01, 3.37000e+00, ..., 1.61000e+01,\n",
       "        3.96900e+02, 4.67000e+00],\n",
       "       [1.96500e-02, 8.00000e+01, 1.76000e+00, ..., 1.82000e+01,\n",
       "        3.41600e+02, 1.29300e+01],\n",
       "       ...,\n",
       "       [2.24236e+00, 0.00000e+00, 1.95800e+01, ..., 1.47000e+01,\n",
       "        3.95110e+02, 1.16400e+01],\n",
       "       [4.75237e+00, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        5.09200e+01, 1.81300e+01],\n",
       "       [2.25971e+01, 0.00000e+00, 1.81000e+01, ..., 2.02000e+01,\n",
       "        3.96900e+02, 3.19900e+01]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to serialize the input data. In this case we want to send the test data as a csv and\n",
    "# so we manually do this. Of course, there are many other ways to do this.\n",
    "payload = [[str(entry) for entry in row] for row in X_test.values]\n",
    "payload = '\\n'.join([','.join(row) for row in payload])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time we use the sagemaker runtime client rather than the sagemaker client so that we can invoke\n",
    "# the endpoint that we created.\n",
    "response = session.sagemaker_runtime_client.invoke_endpoint(\n",
    "                                                EndpointName = endpoint_name,\n",
    "                                                ContentType = 'text/csv',\n",
    "                                                Body = payload)\n",
    "\n",
    "# We need to make sure that we deserialize the result of our endpoint call.\n",
    "result = response['Body'].read().decode(\"utf-8\")\n",
    "Y_pred = np.fromstring(result, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see how well our model works we can create a simple scatter plot between the predicted and actual values. If the model was completely accurate the resulting scatter plot would look like the line $x=y$. As we can see, our model seems to have done okay but there is room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Median Price vs Predicted Price')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(Y_test, Y_pred)\n",
    "plt.xlabel(\"Median Price\")\n",
    "plt.ylabel(\"Predicted Price\")\n",
    "plt.title(\"Median Price vs Predicted Price\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the endpoint\n",
    "\n",
    "Since we are no longer using the deployed model we need to make sure to shut it down. Remember that you have to pay for the length of time that your endpoint is deployed so the longer it is left running, the more it costs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"arn:aws:sagemaker:us-west-1:371271204223:endpoint/boston-xgboost-endpoint-2020-05-10-12-16-10\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-80c4bbcad257>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEndpointName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m                     \"%s() only accepts keyword arguments.\" % py_operation_name)\n\u001b[1;32m    315\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 626\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    627\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the DeleteEndpoint operation: Could not find endpoint \"arn:aws:sagemaker:us-west-1:371271204223:endpoint/boston-xgboost-endpoint-2020-05-10-12-16-10\"."
     ]
    }
   ],
   "source": [
    "session.sagemaker_client.delete_endpoint(EndpointName = endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Clean up\n",
    "\n",
    "The default notebook instance on SageMaker doesn't have a lot of excess disk space available. As you continue to complete and execute notebooks you will eventually fill up this disk space, leading to errors which can be difficult to diagnose. Once you are completely finished using a notebook it is a good idea to remove the files that you created along the way. Of course, you can do this from the terminal or from the notebook hub if you would like. The cell below contains some commands to clean up the created files from within the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will remove all of the files contained in the data_dir directory\n",
    "!rm $data_dir/*\n",
    "\n",
    "# And then we delete the directory itself\n",
    "!rmdir $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
